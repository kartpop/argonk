{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download wiki page 'Dinosaur' and save to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Fetch the page text for the Wikipedia page with title \"Dinosaur\"\n",
    "url = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"titles\": \"Dinosaur\",\n",
    "    \"explaintext\": True\n",
    "}\n",
    "headers = {\"User-Agent\": \"Tinker/0.1 (kartikeyapophali@gmail.com)\"}\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Write the response data to a file\n",
    "with open(\"dinosaur-page.json\", \"w\") as file:\n",
    "    response.text\n",
    "\n",
    "# Extract the page text from the response\n",
    "page_id = list(data[\"query\"][\"pages\"].keys())[0]\n",
    "page_text = data[\"query\"][\"pages\"][page_id][\"extract\"]\n",
    "\n",
    "print(page_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fetch the page text for the Wikipedia page with title \"Dinosaur\"\n",
    "url = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "params = {\n",
    "    \"action\": \"parse\",\n",
    "    \"page\": \"Dinosaur\",\n",
    "    \"format\": \"json\",\n",
    "    \"prop\": \"text\",\n",
    "    \"section\": 0\n",
    "}\n",
    "headers = {\"User-Agent\": \"Tinker/0.1 (kartikeyapophali@gmail.com)\"}\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "with open(\"dinosaur-page.json\", \"w\") as file:\n",
    "    file.write(response.text)\n",
    "    \n",
    "data = response.json()\n",
    "\n",
    "# Extract the HTML text from the response\n",
    "html_content = data[\"parse\"][\"text\"][\"*\"]\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# You can now search for specific tags like <ul>, <ol> for lists, or <h1> to <h6> for headings.\n",
    "# Let's extract all text but retain indentation for bullet points\n",
    "# def extract_with_indentation(soup, level=0):\n",
    "#     indent = '    ' * level  # 4 spaces per level for indentation\n",
    "#     extracted_text = \"\"\n",
    "\n",
    "#     for element in soup.children:\n",
    "#         if element.name == 'ul':  # Unordered list\n",
    "#             extracted_text += extract_with_indentation(element, level + 1)\n",
    "#         elif element.name == 'li':  # List item\n",
    "#             extracted_text += f\"{indent}- {element.get_text()}\\n\"\n",
    "#         elif element.name and element.name.startswith('h'):  # Heading tags\n",
    "#             extracted_text += f\"{indent}{element.get_text()}\\n\"\n",
    "#         elif isinstance(element, str):  # Plain text\n",
    "#             extracted_text += f\"{indent}{element.strip()}\\n\"\n",
    "\n",
    "#     return extracted_text\n",
    "\n",
    "# # Extract and format the structured content\n",
    "# structured_text = extract_with_indentation(soup)\n",
    "\n",
    "# # Save the formatted output\n",
    "# with open(\"dinosaur-page-structured.txt\", \"w\") as file:\n",
    "#     file.write(structured_text)\n",
    "\n",
    "# print(structured_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (argonk)",
   "language": "python",
   "name": "argonk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
