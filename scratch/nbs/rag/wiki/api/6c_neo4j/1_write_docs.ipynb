{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Documents to Neo4j using haystack integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [Document(id=1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec, content: '<link\n",
      "  rel=\"mw-deduplicated-inline-style\"\n",
      "  href=\"mw-data:TemplateStyles:r1236090951\"\n",
      "/>\n",
      "<p class=\"...', meta: {'file_path': 'Dinosaur.html'})]}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "\n",
    "converter = TextFileToDocument()\n",
    "\n",
    "docs = converter.run(sources=[Path(\"Dinosaur.html\")])\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def WikiPageChunks(html_str: str) -> list:\n",
    "    soup = BeautifulSoup(html_str, 'html.parser')  # Parse the HTML content\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    def clean_text(text):\n",
    "        cleaned_text = text.replace('\\n', ' ').replace('\\xa0', ' ')  # Replace newlines and non-breaking spaces with regular spaces\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Replace multiple spaces with a single space\n",
    "        cleaned_text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', cleaned_text)  # Remove spaces between digits\n",
    "        cleaned_text = cleaned_text.strip()  # Remove leading and trailing spaces\n",
    "        return cleaned_text\n",
    "\n",
    "    html_soup = soup.body or soup  # Use the body of the HTML if it exists, otherwise use the whole soup\n",
    "    nested = ['ul', 'ol', 'dl', 'li', 'dt', 'dd']  # Tags that represent nested lists\n",
    "    for tag in html_soup.find_all(recursive=False):  # Iterate over top-level tags in the HTML\n",
    "        if tag.name == 'p':\n",
    "            chunks.append(clean_text(tag.get_text(separator=' ')))  # Clean and add paragraph text to chunks\n",
    "        elif tag.name == 'link':\n",
    "            continue  # Skip link tags\n",
    "        elif tag.name in nested:\n",
    "            list_items = tag.find_all('li')  # Find all list items\n",
    "            for li in list_items:\n",
    "                chunks.append(clean_text(li.get_text(separator=' ')))  # Clean and add each list item text to chunks\n",
    "        else:\n",
    "            chunks.append(str(tag))  # Add other tags as strings\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = docs[\"documents\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import uuid\n",
    "from haystack import Document\n",
    "from haystack import component\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, id: str, next: str = None):\n",
    "        self.id = id\n",
    "        self.next = next\n",
    "\n",
    "class Section:\n",
    "    def __init__(self, name: str, type: str):\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        self.chunks = []\n",
    "        self.sections = []\n",
    "        self.first_chunk = None\n",
    "\n",
    "class Page:\n",
    "    def __init__(self, title: str):\n",
    "        self.title = title\n",
    "        self.sections = []\n",
    "        self.chunks = []\n",
    "        self.first_chunk = None\n",
    "\n",
    "@component\n",
    "class WikiPageChunker:\n",
    "    \"\"\"\n",
    "    A component that splits the content of Wikipedia pages into chunks.\n",
    "    - The document content is expected to be in HTML format fetched via wikipediaapi and\n",
    "    which has been run through TextFileToDocument converter.\n",
    "    - Each chunk is a paragraph, list, or table in the Wikipedia page.\n",
    "    - Each chunk is stored as a separate document with text in 'content' field\n",
    "    - Each chunk also stores title, h2, h3 etc in meta field.\n",
    "    - Custom component also creates a hierarchical structure of the chunks based on title, h2, h3 etc.\n",
    "    \"\"\"\n",
    "    @component.output_types(documents=List[Document], hierarchy=dict)\n",
    "    def run(self, documents: List[Document]):\n",
    "        chunks = []\n",
    "        hierarchy = {}\n",
    "        \n",
    "        for doc in documents:\n",
    "            page_title = doc.meta[\"file_path\"].replace(\".html\", \"\")\n",
    "            page = Page(page_title)\n",
    "            \n",
    "            html_content = doc.content\n",
    "            page_chunks = WikiPageChunks(html_content)\n",
    "            i = 0\n",
    "            current_h2 = \"\"\n",
    "            current_h3 = \"\"\n",
    "            current_h4 = \"\"\n",
    "            current_section = None\n",
    "            current_sub_section = None\n",
    "            current_sub_sub_section = None\n",
    "\n",
    "            for chunk in page_chunks:\n",
    "                if chunk == \"\":\n",
    "                    continue\n",
    "                if chunk.startswith(\"<h2>\"):\n",
    "                    current_h2 = chunk[4:-5]  # Extract text between <h2> and </h2>\n",
    "                    current_h3 = \"\"  # Reset h3 when a new h2 is found\n",
    "                    current_h4 = \"\"  # Reset h4 when a new h2 is found\n",
    "                    current_section = Section(current_h2, \"h2\")\n",
    "                    page.sections.append(current_section)\n",
    "                    current_sub_section = None\n",
    "                    current_sub_sub_section = None\n",
    "                elif chunk.startswith(\"<h3>\"):\n",
    "                    current_h3 = chunk[4:-5]  # Extract text between <h3> and </h3>\n",
    "                    current_h4 = \"\"  # Reset h4 when a new h3 is found\n",
    "                    if current_section:\n",
    "                        current_sub_section = Section(current_h3, \"h3\")\n",
    "                        current_section.sections.append(current_sub_section)\n",
    "                        current_sub_sub_section = None\n",
    "                elif chunk.startswith(\"<h4>\"):\n",
    "                    current_h4 = chunk[4:-5]  # Extract text between <h4> and </h4>\n",
    "                    if current_sub_section:\n",
    "                        current_sub_sub_section = Section(current_h4, \"h4\")\n",
    "                        current_sub_section.sections.append(current_sub_sub_section)\n",
    "                else:\n",
    "                    meta = {\n",
    "                        \"file_path\": doc.meta[\"file_path\"],\n",
    "                        \"source_id\": doc.id,\n",
    "                        \"split_id\": i,\n",
    "                        \"title\": \"Dinosaurs\"\n",
    "                    }\n",
    "                    if current_h2:\n",
    "                        meta[\"h2\"] = current_h2\n",
    "                    if current_h3:\n",
    "                        meta[\"h3\"] = current_h3\n",
    "                    if current_h4:\n",
    "                        meta[\"h4\"] = current_h4\n",
    "\n",
    "                    chunk_obj = Chunk(str(uuid.uuid4()))\n",
    "                    chunks.append(\n",
    "                        Document(\n",
    "                            id=chunk_obj.id,\n",
    "                            content=chunk,\n",
    "                            meta=meta\n",
    "                        )\n",
    "                    )\n",
    "                    if current_sub_sub_section:\n",
    "                        current_sub_sub_section.chunks.append(chunk_obj)\n",
    "                        if current_sub_sub_section.first_chunk is None:\n",
    "                            current_sub_sub_section.first_chunk = chunk_obj\n",
    "                    elif current_sub_section:\n",
    "                        current_sub_section.chunks.append(chunk_obj)\n",
    "                        if current_sub_section.first_chunk is None:\n",
    "                            current_sub_section.first_chunk = chunk_obj\n",
    "                    elif current_section:\n",
    "                        current_section.chunks.append(chunk_obj)\n",
    "                        if current_section.first_chunk is None:\n",
    "                            current_section.first_chunk = chunk_obj\n",
    "                    else:\n",
    "                        page.chunks.append(chunk_obj)\n",
    "                        if page.first_chunk is None:\n",
    "                            page.first_chunk = chunk_obj\n",
    "                    i += 1\n",
    "            \n",
    "            self.set_next_chunks(page)\n",
    "            hierarchy[page_title] = self.page_to_dict(page)\n",
    "        \n",
    "        return {\"documents\": chunks, \"hierarchy\": hierarchy}\n",
    "\n",
    "    def set_next_chunks(self, page: Page):\n",
    "        for section in page.sections:\n",
    "            self.set_next_chunks_in_section(section)\n",
    "        self.set_next_in_list(page.chunks)\n",
    "\n",
    "    def set_next_chunks_in_section(self, section: Section):\n",
    "        for sub_section in section.sections:\n",
    "            self.set_next_chunks_in_section(sub_section)\n",
    "        self.set_next_in_list(section.chunks)\n",
    "\n",
    "    def set_next_in_list(self, chunks: List[Chunk]):\n",
    "        for i in range(len(chunks) - 1):\n",
    "            chunks[i].next = chunks[i + 1].id\n",
    "        if chunks:\n",
    "            chunks[-1].next = None\n",
    "\n",
    "    def page_to_dict(self, page: Page) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"title\": page.title,\n",
    "            \"sections\": [self.section_to_dict(section) for section in page.sections],\n",
    "            \"chunks\": [self.chunk_to_dict(chunk) for chunk in page.chunks],\n",
    "            \"first_chunk\": self.chunk_to_dict(page.first_chunk) if page.first_chunk else None\n",
    "        }\n",
    "\n",
    "    def section_to_dict(self, section: Section) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"name\": section.name,\n",
    "            \"type\": section.type,\n",
    "            \"chunks\": [self.chunk_to_dict(chunk) for chunk in section.chunks],\n",
    "            \"sections\": [self.section_to_dict(sub_section) for sub_section in section.sections],\n",
    "            \"first_chunk\": self.chunk_to_dict(section.first_chunk) if section.first_chunk else None\n",
    "        }\n",
    "\n",
    "    def chunk_to_dict(self, chunk: Chunk) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"id\": chunk.id,\n",
    "            \"next\": chunk.next\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=f7fa2921-9f2c-48b0-82d3-b2d5a99bf35f, content: 'Dinosaurs are a diverse group of reptiles of the clade Dinosauria . They first appeared during the T...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 0, 'title': 'Dinosaurs'}),\n",
       " Document(id=f059e2c4-f7ba-4766-ae1c-3704d74217d0, content: 'Dinosaurs are varied from taxonomic, morphological and ecological standpoints. Birds, at over 11,000...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 1, 'title': 'Dinosaurs'}),\n",
       " Document(id=e8d9734e-3637-402c-9cbc-fe17fe6eaa57, content: 'While dinosaurs were ancestrally bipedal, many extinct groups included quadrupedal species, and some...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 2, 'title': 'Dinosaurs'}),\n",
       " Document(id=cb9048a1-5f85-41e9-b697-c3d5ef4ed137, content: 'The first dinosaur fossils were recognized in the early 19th century, with the name \"dinosaur\" (mean...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 3, 'title': 'Dinosaurs'}),\n",
       " Document(id=3de69bd0-387d-4564-b970-bc49ff198e5b, content: 'Under phylogenetic nomenclature, dinosaurs are usually defined as the group consisting of the most r...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 4, 'title': 'Dinosaurs', 'h2': 'Definition'}),\n",
       " Document(id=c4fb77ea-688d-4139-b6a7-17f19e975ef8, content: 'Birds are the sole surviving dinosaurs. In traditional taxonomy, birds were considered a separate cl...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 5, 'title': 'Dinosaurs', 'h2': 'Definition'}),\n",
       " Document(id=fa3eab62-38be-48e0-b983-4b577efcfa7e, content: 'Research by Matthew G. Baron, David B. Norman, and Paul M. Barrett in 2017 suggested a radical revis...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 6, 'title': 'Dinosaurs', 'h2': 'Definition'}),\n",
       " Document(id=06ed7687-dbe6-4d97-8a5b-2fe5d070d50d, content: 'Using one of the above definitions, dinosaurs can be generally described as archosaurs with hind lim...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 7, 'title': 'Dinosaurs', 'h2': 'Definition', 'h3': 'General description'}),\n",
       " Document(id=4aea36f4-d9a3-4d26-9625-4d6fb7d87342, content: 'Dinosaurs were the dominant terrestrial vertebrates of the Mesozoic Era, especially the Jurassic and...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 8, 'title': 'Dinosaurs', 'h2': 'Definition', 'h3': 'General description'}),\n",
       " Document(id=be464d1a-3c3f-42a2-915e-8db59805e877, content: 'Extinct dinosaurs, as well as modern birds, include genera that are herbivorous and others carnivoro...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 9, 'title': 'Dinosaurs', 'h2': 'Definition', 'h3': 'General description'}),\n",
       " Document(id=33078a24-df2a-4e57-824b-94157b41f928, content: 'Knowledge about dinosaurs is derived from a variety of fossil and non-fossil records, including foss...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 10, 'title': 'Dinosaurs', 'h2': 'Paleobiology'}),\n",
       " Document(id=5464677f-db7e-4dac-a7a3-e56d09500dea, content: 'Current evidence suggests that dinosaur average size varied through the Triassic, Early Jurassic, La...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 11, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size'}),\n",
       " Document(id=d031ecd9-e198-4080-baf7-1b7df8c73757, content: 'The sauropods were the largest and heaviest dinosaurs. For much of the dinosaur era, the smallest sa...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 12, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size'}),\n",
       " Document(id=5b339634-f928-425f-ae29-f8fb54d88ee2, content: 'Scientists will probably never be certain of the largest and smallest dinosaurs to have ever existed...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 13, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}),\n",
       " Document(id=9f1250cb-a032-4f05-be5d-2963bf9cb4fb, content: 'The tallest and heaviest dinosaur known from good skeletons is Giraffatitan brancai (previously clas...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 14, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}),\n",
       " Document(id=958fcf39-77d5-4490-9e2c-6926828c2237, content: 'There were larger dinosaurs, but knowledge of them is based entirely on a small number of fragmentar...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 15, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}),\n",
       " Document(id=ddf4c45b-c62a-44b0-af8f-0f815e0ff1c0, content: 'The largest carnivorous dinosaur was Spinosaurus , reaching a length of 12.6 to 18 meters (41 to 59 ...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 16, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}),\n",
       " Document(id=0ba64215-ad42-4572-9de8-83a4388f5079, content: 'The smallest dinosaur known is the bee hummingbird, with a length of only 5 centimeters (2.0 in) and...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 17, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}),\n",
       " Document(id=f3e017c8-8673-4405-ab92-07c31f5c8aac, content: 'Many modern birds are highly social, often found living in flocks. There is general agreement that s...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 18, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}),\n",
       " Document(id=0606f8f7-bff7-4055-9936-73d384899869, content: 'The first potential evidence for herding or flocking as a widespread behavior common to many dinosau...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 19, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}),\n",
       " Document(id=fa339759-71e2-4af2-9b83-2385b8bac26e, content: 'The crests and frills of some dinosaurs, like the marginocephalians, theropods and lambeosaurines, m...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 20, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}),\n",
       " Document(id=17104147-d3b3-420a-bb3e-c9091b8a8585, content: 'From a behavioral standpoint, one of the most valuable dinosaur fossils was discovered in the Gobi D...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 21, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}),\n",
       " Document(id=b6b84ecb-ff44-40a1-bcea-4fe50e74981b, content: 'Comparisons between the scleral rings of dinosaurs and modern birds and reptiles have been used to i...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 22, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}),\n",
       " Document(id=8cddc5d2-5e41-49ca-b7ae-da96d4e059d8, content: 'Based on fossil evidence from dinosaurs such as Oryctodromeus , some ornithischian species seem to h...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 23, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}),\n",
       " Document(id=6b523cad-bf0b-445c-ac0d-da5c90d645fa, content: 'Modern birds communicate by visual and auditory signals, and the wide diversity of visual display st...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 24, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Communication'}),\n",
       " Document(id=4a457ee2-b22b-4e71-a4e4-89647d4d6d4b, content: 'On the basis that non-avian dinosaurs did not have syrinxes and that their next close living relativ...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 25, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Communication'}),\n",
       " Document(id=1d16f151-d17d-4d8d-8e92-0a8846035eb4, content: 'In 2023, a fossilized larynx was described, from a specimen of the ankylosaurid Pinacosaurus . The s...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 26, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Communication'}),\n",
       " Document(id=bed54e6e-8ae6-4a3a-93f5-30dae7465e06, content: 'All dinosaurs laid amniotic eggs. Dinosaur eggs were usually laid in a nest. Most species create som...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 27, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Reproductive biology'}),\n",
       " Document(id=1ed2b8a1-cefc-4c0d-b570-e71ce1838e22, content: 'When laying eggs, females grow a special type of bone between the hard outer bone and the marrow of ...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 28, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Reproductive biology'}),\n",
       " Document(id=a65dd143-0572-458a-adf5-73d4c2aeb663, content: 'Another widespread trait among modern birds (but see below in regards to fossil groups and extant me...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 29, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Reproductive biology'}),\n",
       " Document(id=8a36248c-5e75-45a1-b69f-d226c19f956c, content: 'However, there is ample evidence of precociality or superprecociality among many dinosaur species, p...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 30, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Reproductive biology'}),\n",
       " Document(id=6b063f99-9b98-47dc-a9fa-425a6831123c, content: 'Genital structures are unlikely to fossilize as they lack scales that may allow preservation via pig...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 31, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Reproductive biology'}),\n",
       " Document(id=9ec60537-c087-40c1-b0cf-f298b5b6998c, content: 'Because both modern crocodilians and birds have four-chambered hearts (albeit modified in crocodilia...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 32, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Physiology'}),\n",
       " Document(id=46939a01-3282-4faa-aa38-74ba44b05b18, content: 'After non-avian dinosaurs were discovered, paleontologists first posited that they were ectothermic....', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 33, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Physiology'}),\n",
       " Document(id=e01f1b9f-0866-416d-aa13-d7f90e0dc3d2, content: 'One of the greatest contributions to the modern understanding of dinosaur physiology has been paleoh...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 34, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Physiology'}),\n",
       " Document(id=f4671a08-6951-4cec-8d5d-157b94763298, content: 'In saurischian dinosaurs, higher metabolisms were supported by the evolution of the avian respirator...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 35, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Physiology'}),\n",
       " Document(id=e28556e2-a38a-4dd0-97f0-a65369478ee5, content: 'Like other reptiles, dinosaurs are primarily uricotelic, that is, their kidneys extract nitrogenous ...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 36, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Physiology'}),\n",
       " Document(id=7138bddc-d677-4297-ae3a-4c55b4c90ec0, content: 'The size and shape of the brain can be partly reconstructed based on the surrounding bones. In 1896,...', meta: {'file_path': 'Dinosaur.html', 'source_id': '1841e79f27771b7e59691e069d4b42204bbe5ea1093e15aa20aeeb86127557ec', 'split_id': 37, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Physiology'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = WikiPageChunker()\n",
    "\n",
    "chunk_result = splitter.run(docs[\"documents\"])\n",
    "\n",
    "chunk_result[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dinosaur': {'title': 'Dinosaur',\n",
       "  'sections': [{'name': 'Definition',\n",
       "    'type': 'h2',\n",
       "    'chunks': [{'id': '3de69bd0-387d-4564-b970-bc49ff198e5b',\n",
       "      'next': 'c4fb77ea-688d-4139-b6a7-17f19e975ef8'},\n",
       "     {'id': 'c4fb77ea-688d-4139-b6a7-17f19e975ef8',\n",
       "      'next': 'fa3eab62-38be-48e0-b983-4b577efcfa7e'},\n",
       "     {'id': 'fa3eab62-38be-48e0-b983-4b577efcfa7e', 'next': None}],\n",
       "    'sections': [{'name': 'General description',\n",
       "      'type': 'h3',\n",
       "      'chunks': [{'id': '06ed7687-dbe6-4d97-8a5b-2fe5d070d50d',\n",
       "        'next': '4aea36f4-d9a3-4d26-9625-4d6fb7d87342'},\n",
       "       {'id': '4aea36f4-d9a3-4d26-9625-4d6fb7d87342',\n",
       "        'next': 'be464d1a-3c3f-42a2-915e-8db59805e877'},\n",
       "       {'id': 'be464d1a-3c3f-42a2-915e-8db59805e877', 'next': None}],\n",
       "      'sections': [],\n",
       "      'first_chunk': {'id': '06ed7687-dbe6-4d97-8a5b-2fe5d070d50d',\n",
       "       'next': '4aea36f4-d9a3-4d26-9625-4d6fb7d87342'}}],\n",
       "    'first_chunk': {'id': '3de69bd0-387d-4564-b970-bc49ff198e5b',\n",
       "     'next': 'c4fb77ea-688d-4139-b6a7-17f19e975ef8'}},\n",
       "   {'name': 'Paleobiology',\n",
       "    'type': 'h2',\n",
       "    'chunks': [{'id': '33078a24-df2a-4e57-824b-94157b41f928', 'next': None}],\n",
       "    'sections': [{'name': 'Size',\n",
       "      'type': 'h3',\n",
       "      'chunks': [{'id': '5464677f-db7e-4dac-a7a3-e56d09500dea',\n",
       "        'next': 'd031ecd9-e198-4080-baf7-1b7df8c73757'},\n",
       "       {'id': 'd031ecd9-e198-4080-baf7-1b7df8c73757', 'next': None}],\n",
       "      'sections': [{'name': 'Largest and smallest',\n",
       "        'type': 'h4',\n",
       "        'chunks': [{'id': '5b339634-f928-425f-ae29-f8fb54d88ee2',\n",
       "          'next': '9f1250cb-a032-4f05-be5d-2963bf9cb4fb'},\n",
       "         {'id': '9f1250cb-a032-4f05-be5d-2963bf9cb4fb',\n",
       "          'next': '958fcf39-77d5-4490-9e2c-6926828c2237'},\n",
       "         {'id': '958fcf39-77d5-4490-9e2c-6926828c2237',\n",
       "          'next': 'ddf4c45b-c62a-44b0-af8f-0f815e0ff1c0'},\n",
       "         {'id': 'ddf4c45b-c62a-44b0-af8f-0f815e0ff1c0',\n",
       "          'next': '0ba64215-ad42-4572-9de8-83a4388f5079'},\n",
       "         {'id': '0ba64215-ad42-4572-9de8-83a4388f5079', 'next': None}],\n",
       "        'sections': [],\n",
       "        'first_chunk': {'id': '5b339634-f928-425f-ae29-f8fb54d88ee2',\n",
       "         'next': '9f1250cb-a032-4f05-be5d-2963bf9cb4fb'}}],\n",
       "      'first_chunk': {'id': '5464677f-db7e-4dac-a7a3-e56d09500dea',\n",
       "       'next': 'd031ecd9-e198-4080-baf7-1b7df8c73757'}},\n",
       "     {'name': 'Behavior',\n",
       "      'type': 'h3',\n",
       "      'chunks': [{'id': 'f3e017c8-8673-4405-ab92-07c31f5c8aac',\n",
       "        'next': '0606f8f7-bff7-4055-9936-73d384899869'},\n",
       "       {'id': '0606f8f7-bff7-4055-9936-73d384899869',\n",
       "        'next': 'fa339759-71e2-4af2-9b83-2385b8bac26e'},\n",
       "       {'id': 'fa339759-71e2-4af2-9b83-2385b8bac26e',\n",
       "        'next': '17104147-d3b3-420a-bb3e-c9091b8a8585'},\n",
       "       {'id': '17104147-d3b3-420a-bb3e-c9091b8a8585',\n",
       "        'next': 'b6b84ecb-ff44-40a1-bcea-4fe50e74981b'},\n",
       "       {'id': 'b6b84ecb-ff44-40a1-bcea-4fe50e74981b',\n",
       "        'next': '8cddc5d2-5e41-49ca-b7ae-da96d4e059d8'},\n",
       "       {'id': '8cddc5d2-5e41-49ca-b7ae-da96d4e059d8', 'next': None}],\n",
       "      'sections': [],\n",
       "      'first_chunk': {'id': 'f3e017c8-8673-4405-ab92-07c31f5c8aac',\n",
       "       'next': '0606f8f7-bff7-4055-9936-73d384899869'}},\n",
       "     {'name': 'Communication',\n",
       "      'type': 'h3',\n",
       "      'chunks': [{'id': '6b523cad-bf0b-445c-ac0d-da5c90d645fa',\n",
       "        'next': '4a457ee2-b22b-4e71-a4e4-89647d4d6d4b'},\n",
       "       {'id': '4a457ee2-b22b-4e71-a4e4-89647d4d6d4b',\n",
       "        'next': '1d16f151-d17d-4d8d-8e92-0a8846035eb4'},\n",
       "       {'id': '1d16f151-d17d-4d8d-8e92-0a8846035eb4', 'next': None}],\n",
       "      'sections': [],\n",
       "      'first_chunk': {'id': '6b523cad-bf0b-445c-ac0d-da5c90d645fa',\n",
       "       'next': '4a457ee2-b22b-4e71-a4e4-89647d4d6d4b'}},\n",
       "     {'name': 'Reproductive biology',\n",
       "      'type': 'h3',\n",
       "      'chunks': [{'id': 'bed54e6e-8ae6-4a3a-93f5-30dae7465e06',\n",
       "        'next': '1ed2b8a1-cefc-4c0d-b570-e71ce1838e22'},\n",
       "       {'id': '1ed2b8a1-cefc-4c0d-b570-e71ce1838e22',\n",
       "        'next': 'a65dd143-0572-458a-adf5-73d4c2aeb663'},\n",
       "       {'id': 'a65dd143-0572-458a-adf5-73d4c2aeb663',\n",
       "        'next': '8a36248c-5e75-45a1-b69f-d226c19f956c'},\n",
       "       {'id': '8a36248c-5e75-45a1-b69f-d226c19f956c',\n",
       "        'next': '6b063f99-9b98-47dc-a9fa-425a6831123c'},\n",
       "       {'id': '6b063f99-9b98-47dc-a9fa-425a6831123c', 'next': None}],\n",
       "      'sections': [],\n",
       "      'first_chunk': {'id': 'bed54e6e-8ae6-4a3a-93f5-30dae7465e06',\n",
       "       'next': '1ed2b8a1-cefc-4c0d-b570-e71ce1838e22'}},\n",
       "     {'name': 'Physiology',\n",
       "      'type': 'h3',\n",
       "      'chunks': [{'id': '9ec60537-c087-40c1-b0cf-f298b5b6998c',\n",
       "        'next': '46939a01-3282-4faa-aa38-74ba44b05b18'},\n",
       "       {'id': '46939a01-3282-4faa-aa38-74ba44b05b18',\n",
       "        'next': 'e01f1b9f-0866-416d-aa13-d7f90e0dc3d2'},\n",
       "       {'id': 'e01f1b9f-0866-416d-aa13-d7f90e0dc3d2',\n",
       "        'next': 'f4671a08-6951-4cec-8d5d-157b94763298'},\n",
       "       {'id': 'f4671a08-6951-4cec-8d5d-157b94763298',\n",
       "        'next': 'e28556e2-a38a-4dd0-97f0-a65369478ee5'},\n",
       "       {'id': 'e28556e2-a38a-4dd0-97f0-a65369478ee5',\n",
       "        'next': '7138bddc-d677-4297-ae3a-4c55b4c90ec0'},\n",
       "       {'id': '7138bddc-d677-4297-ae3a-4c55b4c90ec0', 'next': None}],\n",
       "      'sections': [],\n",
       "      'first_chunk': {'id': '9ec60537-c087-40c1-b0cf-f298b5b6998c',\n",
       "       'next': '46939a01-3282-4faa-aa38-74ba44b05b18'}}],\n",
       "    'first_chunk': {'id': '33078a24-df2a-4e57-824b-94157b41f928',\n",
       "     'next': None}}],\n",
       "  'chunks': [{'id': 'f7fa2921-9f2c-48b0-82d3-b2d5a99bf35f',\n",
       "    'next': 'f059e2c4-f7ba-4766-ae1c-3704d74217d0'},\n",
       "   {'id': 'f059e2c4-f7ba-4766-ae1c-3704d74217d0',\n",
       "    'next': 'e8d9734e-3637-402c-9cbc-fe17fe6eaa57'},\n",
       "   {'id': 'e8d9734e-3637-402c-9cbc-fe17fe6eaa57',\n",
       "    'next': 'cb9048a1-5f85-41e9-b697-c3d5ef4ed137'},\n",
       "   {'id': 'cb9048a1-5f85-41e9-b697-c3d5ef4ed137', 'next': None}],\n",
       "  'first_chunk': {'id': 'f7fa2921-9f2c-48b0-82d3-b2d5a99bf35f',\n",
       "   'next': 'f059e2c4-f7ba-4766-ae1c-3704d74217d0'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy = chunk_result[\"hierarchy\"]\n",
    "\n",
    "hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: use neo4j_haystack driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_haystack.client.neo4j_client import Neo4jClientConfig\n",
    "from neo4j_haystack.components.neo4j_query_writer import Neo4jQueryWriter\n",
    "\n",
    "client_config = Neo4jClientConfig(\"bolt://localhost:7687\", database=\"neo4j\", username=\"neo4j\", password=\"neo4jpass\")\n",
    "\n",
    "\n",
    "writer = Neo4jQueryWriter(client_config=client_config, verify_connectivity=True, runtime_parameters=[\"hierarchy\"])\n",
    "\n",
    "result = writer.run(\n",
    "    query=(\n",
    "        # Create cypher query to create nodes and relationships from hierarchy\n",
    "    ),\n",
    "    hierarchy=hierarchy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: custom logic to create graph (seems easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class Neo4jGraphCreator:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def create_graph(self, page_dict):\n",
    "        with self.driver.session() as session:\n",
    "            # Create Page node with UUID\n",
    "            page_uuid = str(uuid.uuid4())\n",
    "            page_query = \"\"\"\n",
    "            MERGE (p:Page {title: $title})\n",
    "            ON CREATE SET p.uuid = $uuid\n",
    "            RETURN p\n",
    "            \"\"\"\n",
    "            session.run(page_query, title=page_dict['title'], uuid=page_uuid)\n",
    "\n",
    "            # Create sections and chunks\n",
    "            self.create_sections_and_chunks(session, page_uuid, page_dict['sections'])\n",
    "            self.create_chunks(session, page_uuid, page_dict['chunks'], page_dict.get('first_chunk'))\n",
    "\n",
    "    def create_sections_and_chunks(self, session, parent_uuid, sections):\n",
    "        for section in sections:\n",
    "            section_uuid = str(uuid.uuid4())\n",
    "            section_labels = f\":Section:{section['type']}\"\n",
    "            \n",
    "            # Query to find either Page or Section as parent\n",
    "            section_query = f\"\"\"\n",
    "            MATCH (parent {{uuid: $parent_uuid}})\n",
    "            MERGE (s{section_labels} {{name: $name}})\n",
    "            ON CREATE SET s.uuid = $uuid\n",
    "            MERGE (parent)-[:HAS_SECTION]->(s)\n",
    "            RETURN s\n",
    "            \"\"\"\n",
    "            session.run(section_query, parent_uuid=parent_uuid, name=section['name'], uuid=section_uuid)\n",
    "\n",
    "            # Recursively create sub-sections and chunks\n",
    "            self.create_sections_and_chunks(session, section_uuid, section['sections'])\n",
    "            self.create_chunks(session, section_uuid, section['chunks'], section.get('first_chunk'))\n",
    "\n",
    "    def create_chunks(self, session, parent_uuid, chunks, first_chunk=None):\n",
    "        first_chunk_created = False\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Reuse the existing chunk.id as the UUID\n",
    "            chunk_uuid = chunk['id']\n",
    "            \n",
    "            chunk_query = \"\"\"\n",
    "            MATCH (parent {uuid: $parent_uuid})\n",
    "            MERGE (c:Chunk {id: $id})\n",
    "            ON CREATE SET c.uuid = $uuid\n",
    "            MERGE (parent)-[:HAS_CHUNK]->(c)\n",
    "            RETURN c\n",
    "            \"\"\"\n",
    "            session.run(chunk_query, parent_uuid=parent_uuid, id=chunk['id'], uuid=chunk_uuid)\n",
    "\n",
    "            # Create the HAS_FIRST_CHUNK relationship if first_chunk is specified and not yet created\n",
    "            if first_chunk and not first_chunk_created and chunk['id'] == first_chunk['id']:\n",
    "                first_chunk_query = \"\"\"\n",
    "                MATCH (parent {uuid: $parent_uuid}), (c:Chunk {id: $chunk_id})\n",
    "                MERGE (parent)-[:HAS_FIRST_CHUNK]->(c)\n",
    "                RETURN parent, c\n",
    "                \"\"\"\n",
    "                session.run(first_chunk_query, parent_uuid=parent_uuid, chunk_id=chunk['id'])\n",
    "                first_chunk_created = True\n",
    "\n",
    "            # Set the NEXT relationship\n",
    "            if i < len(chunks) - 1:\n",
    "                next_chunk_query = \"\"\"\n",
    "                MATCH (c1:Chunk {id: $id1}), (c2:Chunk {id: $id2})\n",
    "                MERGE (c1)-[:NEXT]->(c2)\n",
    "                RETURN c1, c2\n",
    "                \"\"\"\n",
    "                session.run(next_chunk_query, id1=chunk['id'], id2=chunks[i + 1]['id'])\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# page_dict = {\n",
    "#     \"title\": \"Dinosaurs\",\n",
    "#     \"sections\": [\n",
    "#         {\n",
    "#             \"name\": \"Introduction\",\n",
    "#             \"type\": \"h2\",\n",
    "#             \"chunks\": [{\"id\": \"chunk1\", \"next\": \"chunk2\"}],\n",
    "#             \"sections\": [\n",
    "#                 {\n",
    "#                     \"name\": \"History\",\n",
    "#                     \"type\": \"h3\",\n",
    "#                     \"chunks\": [{\"id\": \"chunk2\", \"next\": None}],\n",
    "#                     \"sections\": []\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"first_chunk\": {\"id\": \"chunk1\", \"next\": \"chunk2\"}\n",
    "#         }\n",
    "#     ],\n",
    "#     \"chunks\": [],\n",
    "#     \"first_chunk\": None\n",
    "# }\n",
    "\n",
    "# neo4j_creator = Neo4jGraphCreator(\"bolt://localhost:7687\", \"neo4j\", \"password\")\n",
    "# neo4j_creator.create_graph(page_dict)\n",
    "# neo4j_creator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (argonk)",
   "language": "python",
   "name": "argonk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
