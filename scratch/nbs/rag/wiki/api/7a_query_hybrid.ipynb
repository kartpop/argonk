{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/haystack/components/generators/openai.py:106: DeprecationWarning: In the upcoming releases 'gpt-3.5-turbo' will be replaced by 'gpt-4o-mini' as the default model\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "from haystack_integrations.document_stores.weaviate.document_store import WeaviateDocumentStore\n",
    "from haystack_integrations.components.retrievers.weaviate.embedding_retriever import WeaviateEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever\n",
    "\n",
    "\n",
    "embedder = OpenAIDocumentEmbedder(model=\"text-embedding-3-small\")\n",
    "text_embedder = OpenAITextEmbedder(model=\"text-embedding-3-small\")\n",
    "weaviate_store = WeaviateDocumentStore(url=\"http://localhost:8088\")\n",
    "elasticsearch_store = ElasticsearchDocumentStore(hosts= \"http://localhost:9200\")\n",
    "weaviate_retriever = WeaviateEmbeddingRetriever(document_store=weaviate_store, top_k=3)\n",
    "elasticsearch_retriever = ElasticsearchBM25Retriever(document_store=elasticsearch_store, top_k=3)\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question only using the following context. Do not use any external information. \n",
    "If the answer is not present in the context, please answer with \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=template)\n",
    "\n",
    "generator = OpenAIGenerator(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7dae9972a180>\n",
       "🚅 Components\n",
       "  - text_embedder: OpenAITextEmbedder\n",
       "  - weaviate_retriever: WeaviateEmbeddingRetriever\n",
       "  - elasticsearch_retriever: ElasticsearchBM25Retriever\n",
       "  - joiner: DocumentJoiner\n",
       "🛤️ Connections\n",
       "  - text_embedder.embedding -> weaviate_retriever.query_embedding (List[float])\n",
       "  - weaviate_retriever.documents -> joiner.documents (List[Document])\n",
       "  - elasticsearch_retriever.documents -> joiner.documents (List[Document])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.joiners.document_joiner import DocumentJoiner\n",
    "\n",
    "joiner = DocumentJoiner(join_mode=\"reciprocal_rank_fusion\", top_k=3)\n",
    "\n",
    "p = Pipeline()\n",
    "\n",
    "p.add_component(\"text_embedder\", text_embedder)\n",
    "p.add_component(\"weaviate_retriever\", weaviate_retriever)\n",
    "p.add_component(\"elasticsearch_retriever\", elasticsearch_retriever)\n",
    "p.add_component(\"joiner\", joiner)\n",
    "\n",
    "p.connect(\"text_embedder.embedding\", \"weaviate_retriever.query_embedding\")\n",
    "p.connect(\"weaviate_retriever\", \"joiner\")\n",
    "p.connect(\"elasticsearch_retriever\", \"joiner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/posthog/client.py:345: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().replace(tzinfo=tzutc())\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/posthog/request.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  body[\"sentAt\"] = datetime.utcnow().replace(tzinfo=tzutc()).isoformat()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_embedder': {'meta': {'model': 'text-embedding-3-small',\n",
       "   'usage': {'prompt_tokens': 10, 'total_tokens': 10}}},\n",
       " 'joiner': {'documents': [Document(id=433ad671-ea22-4ae1-9bc4-1cce06a0e6ee, content: 'Just before the K-Pg extinction event, the number of non-avian dinosaur species that existed globall...', meta: {'h3': 'Pre-extinction diversity', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 235.0, 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Extinction of major groups'}, score: 1.0, embedding: vector of size 1536),\n",
       "   Document(id=3f45e988-b093-4d9c-bde1-67e2e4c3b599, content: 'All non-avian dinosaurs and most lineages of birds became extinct in a mass extinction event, called...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 234, 'title': 'Dinosaurs', 'h2': 'Extinction of major groups'}, score: 0.4919354838709677, embedding: vector of size 1536),\n",
       "   Document(id=935b9b14-74dc-49d9-8111-eaba7e525ed8, content: 'The Cretaceous–Paleogene extinction event, which occurred approximately 66 million years ago at the ...', meta: {'h3': 'Evolution and paleobiogeography', 'split_id': 46.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Evolutionary history'}, score: 0.4919354838709677, embedding: vector of size 1536)]},\n",
       " 'elasticsearch_retriever': {'documents': [Document(id=433ad671-ea22-4ae1-9bc4-1cce06a0e6ee, content: 'Just before the K-Pg extinction event, the number of non-avian dinosaur species that existed globall...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 235, 'title': 'Dinosaurs', 'h2': 'Extinction of major groups', 'h3': 'Pre-extinction diversity'}, score: 17.038458, embedding: vector of size 1536),\n",
       "   Document(id=3f45e988-b093-4d9c-bde1-67e2e4c3b599, content: 'All non-avian dinosaurs and most lineages of birds became extinct in a mass extinction event, called...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 234, 'title': 'Dinosaurs', 'h2': 'Extinction of major groups'}, score: 15.461512, embedding: vector of size 1536),\n",
       "   Document(id=72964dd2-a5a8-4f60-a1ce-6ab52a861eb6, content: 'Based on fossil evidence from dinosaurs such as Oryctodromeus , some ornithischian species seem to h...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 211, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}, score: 12.829857, embedding: vector of size 1536)]},\n",
       " 'weaviate_retriever': {'documents': [Document(id=433ad671-ea22-4ae1-9bc4-1cce06a0e6ee, content: 'Just before the K-Pg extinction event, the number of non-avian dinosaur species that existed globall...', meta: {'h3': 'Pre-extinction diversity', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 235.0, 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Extinction of major groups'}, score: 0.852454662322998, embedding: vector of size 1536),\n",
       "   Document(id=935b9b14-74dc-49d9-8111-eaba7e525ed8, content: 'The Cretaceous–Paleogene extinction event, which occurred approximately 66 million years ago at the ...', meta: {'h3': 'Evolution and paleobiogeography', 'split_id': 46.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Evolutionary history'}, score: 0.8221505284309387, embedding: vector of size 1536),\n",
       "   Document(id=47234d41-15c7-451e-95b3-2a7b31baf8b1, content: 'When dinosaurs appeared, they were not the dominant terrestrial animals. The terrestrial habitats we...', meta: {'h3': 'Origins and early evolution', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 42.0, 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Evolutionary history'}, score: 0.8219538927078247, embedding: vector of size 1536)]}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many dinosaur species existed before the extinction event?\"\n",
    "\n",
    "result = p.run(data={\"elasticsearch_retriever\": {\"query\": query}, \n",
    "            \"text_embedder\": {\"text\": query}}, include_outputs_from={\"weaviate_retriever\", \"elasticsearch_retriever\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping LLM calls...straightforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore graph calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_embedder': {'meta': {'model': 'text-embedding-3-small',\n",
       "   'usage': {'prompt_tokens': 10, 'total_tokens': 10}}},\n",
       " 'joiner': {'documents': [Document(id=8a7f94b9-3ae4-45a8-90ba-c9f5377c4b5b, content: 'World War II caused a pause in palaeontological research; after the war, research attention was also...', meta: {'h3': '\"Dinosaur renaissance\" and beyond', 'split_id': 33.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'History of study'}, score: 0.9760624679979518, embedding: vector of size 1536),\n",
       "   Document(id=3aacf659-c395-452b-92a1-e2e1d2b81ec3, content: 'The popular preoccupation with dinosaurs has ensured their appearance in literature, film, and other...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 244, 'title': 'Dinosaurs', 'h2': 'Cultural depictions'}, score: 0.5, embedding: vector of size 1536),\n",
       "   Document(id=54620459-cf76-480a-accf-e8ca14bb6e91, content: 'One of the greatest contributions to the modern understanding of dinosaur physiology has been paleoh...', meta: {'h3': 'Physiology', 'split_id': 222.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Paleobiology'}, score: 0.5, embedding: vector of size 1536)]},\n",
       " 'elasticsearch_retriever': {'documents': [Document(id=3aacf659-c395-452b-92a1-e2e1d2b81ec3, content: 'The popular preoccupation with dinosaurs has ensured their appearance in literature, film, and other...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 244, 'title': 'Dinosaurs', 'h2': 'Cultural depictions'}, score: 11.202653, embedding: vector of size 1536),\n",
       "   Document(id=8a7f94b9-3ae4-45a8-90ba-c9f5377c4b5b, content: 'World War II caused a pause in palaeontological research; after the war, research attention was also...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 33, 'title': 'Dinosaurs', 'h2': 'History of study', 'h3': '\"Dinosaur renaissance\" and beyond'}, score: 9.824031, embedding: vector of size 1536),\n",
       "   Document(id=51cfc07d-fa24-431c-a3aa-84bd5e6d6743, content: 'Current evidence suggests that dinosaur average size varied through the Triassic, Early Jurassic, La...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 199, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size'}, score: 9.7053795, embedding: vector of size 1536)]},\n",
       " 'weaviate_retriever': {'documents': [Document(id=54620459-cf76-480a-accf-e8ca14bb6e91, content: 'One of the greatest contributions to the modern understanding of dinosaur physiology has been paleoh...', meta: {'h3': 'Physiology', 'split_id': 222.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Paleobiology'}, score: 0.8069940805435181, embedding: vector of size 1536),\n",
       "   Document(id=ed090260-bd01-484a-8029-03523e3ac3fd, content: 'Knowledge about dinosaurs is derived from a variety of fossil and non-fossil records, including foss...', meta: {'h3': None, 'split_id': 198.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Paleobiology'}, score: 0.803046703338623, embedding: vector of size 1536),\n",
       "   Document(id=8a7f94b9-3ae4-45a8-90ba-c9f5377c4b5b, content: 'World War II caused a pause in palaeontological research; after the war, research attention was also...', meta: {'h3': '\"Dinosaur renaissance\" and beyond', 'split_id': 33.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'History of study'}, score: 0.7848944664001465, embedding: vector of size 1536)]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tell me in short about the physiology of dinosaurs.\"\n",
    "\n",
    "result = p.run(data={\"elasticsearch_retriever\": {\"query\": query}, \n",
    "            \"text_embedder\": {\"text\": query}}, include_outputs_from={\"weaviate_retriever\", \"elasticsearch_retriever\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to employ graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach\n",
    "- Loop over all documents returned by Joiner and anchor on corresponding chunks in Neo4j graph\n",
    "- Find parent of chunk\n",
    "- Spread out 2 levels to find all non-chunk nodes\n",
    "- Compare cosine similarity with question???\n",
    "- Find the most matching node and return all chunks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach\n",
    "- If LLM finds that context is not enough to answer the question, it should ask for more context\n",
    "- For each retrieved chunk, find title node, create page hierarchy from graph using title node and provide the page hierarchy to the LLM\n",
    "- Let LLM decide the deepest level in the hierarchy which it feels can sufficiently answer the question. Provide all chunks for that deepest level as context for the LLM to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct hierarchy of page given a chunk id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dinosaur',\n",
       " 'sections': [{'name': 'Definition',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'General description', 'type': 'h3'},\n",
       "    {'name': 'Distinguishing anatomical features', 'type': 'h3'}]},\n",
       "  {'name': 'History of study',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'Pre-scientific history', 'type': 'h3'},\n",
       "    {'name': 'Early dinosaur research', 'type': 'h3'},\n",
       "    {'name': 'Discoveries in North America', 'type': 'h3'},\n",
       "    {'name': '\"Dinosaur renaissance\" and beyond', 'type': 'h3'},\n",
       "    {'name': 'Soft tissue and molecular preservation', 'type': 'h3'}]},\n",
       "  {'name': 'Evolutionary history',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'Origins and early evolution', 'type': 'h3'},\n",
       "    {'name': 'Evolution and paleobiogeography', 'type': 'h3'}]},\n",
       "  {'name': 'Classification',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'Taxonomy', 'type': 'h3'},\n",
       "    {'name': 'Timeline of major groups', 'type': 'h3'}]},\n",
       "  {'name': 'Paleobiology',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'Size',\n",
       "     'type': 'h3',\n",
       "     'sections': [{'name': 'Largest and smallest', 'type': 'h4'}]},\n",
       "    {'name': 'Behavior', 'type': 'h3'},\n",
       "    {'name': 'Communication', 'type': 'h3'},\n",
       "    {'name': 'Reproductive biology', 'type': 'h3'},\n",
       "    {'name': 'Physiology', 'type': 'h3'}]},\n",
       "  {'name': 'Origin of birds',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'Feathers', 'type': 'h3'},\n",
       "    {'name': 'Skeleton', 'type': 'h3'},\n",
       "    {'name': 'Soft anatomy', 'type': 'h3'},\n",
       "    {'name': 'Behavioral evidence', 'type': 'h3'}]},\n",
       "  {'name': 'Extinction of major groups',\n",
       "   'type': 'h2',\n",
       "   'sections': [{'name': 'Pre-extinction diversity', 'type': 'h3'},\n",
       "    {'name': 'Impact event', 'type': 'h3'},\n",
       "    {'name': 'Deccan Traps', 'type': 'h3'},\n",
       "    {'name': 'Possible Paleocene survivors', 'type': 'h3'}]},\n",
       "  {'name': 'Cultural depictions', 'type': 'h2'},\n",
       "  {'name': 'See also', 'type': 'h2'},\n",
       "  {'name': 'Notes', 'type': 'h2'},\n",
       "  {'name': 'References', 'type': 'h2'},\n",
       "  {'name': 'Bibliography', 'type': 'h2'},\n",
       "  {'name': 'Further reading', 'type': 'h2'}]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class WikiHierarchy:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def get_hierarchy(self, chunk_id):\n",
    "        with self.driver.session() as session:\n",
    "            # Step 1: Find the title node from the chunk ID\n",
    "            page_node = session.run(\"\"\"\n",
    "            MATCH (chunk:Chunk {uuid: $chunk_id})\n",
    "            OPTIONAL MATCH (page:Page)-[:HAS_SECTION*0..]->(section)-[:HAS_CHUNK]->(chunk)\n",
    "            WITH page\n",
    "            WHERE page IS NOT NULL\n",
    "            RETURN DISTINCT page\n",
    "            \"\"\", chunk_id=chunk_id).single()\n",
    "\n",
    "            if not page_node:\n",
    "                return None\n",
    "\n",
    "            page_node = page_node[\"page\"]\n",
    "            \n",
    "            # Step 2: Recursively build the hierarchy\n",
    "            hierarchy = self.build_hierarchy(session, page_node[\"uuid\"])\n",
    "            return hierarchy\n",
    "\n",
    "    def build_hierarchy(self, session, node_uuid):\n",
    "        # Get the node details\n",
    "        node = session.run(\"\"\"\n",
    "        MATCH (n {uuid: $uuid})\n",
    "        RETURN n\n",
    "        \"\"\", uuid=node_uuid).single()[\"n\"]\n",
    "\n",
    "        # Initialize the hierarchy dictionary\n",
    "        hierarchy = {\n",
    "            \"title\": node[\"title\"]\n",
    "        }\n",
    "\n",
    "        # Get the sections connected to this node\n",
    "        sections = session.run(\"\"\"\n",
    "        MATCH (n {uuid: $uuid})-[:HAS_SECTION]->(s)\n",
    "        RETURN s, labels(s) AS labels\n",
    "        \"\"\", uuid=node_uuid)\n",
    "\n",
    "        section_list = []\n",
    "        for section in sections:\n",
    "            section_node = section[\"s\"]\n",
    "            labels = section[\"labels\"]\n",
    "            # Determine the type from the labels\n",
    "            section_type = next(label for label in labels if label in {'h2', 'h3', 'h4'})\n",
    "            section_hierarchy = {\n",
    "                \"name\": section_node[\"name\"],\n",
    "                \"type\": section_type\n",
    "            }\n",
    "            # Recursively build the hierarchy for subsections\n",
    "            subsection_hierarchy = self.build_hierarchy(session, section_node[\"uuid\"])\n",
    "            if \"sections\" in subsection_hierarchy:\n",
    "                section_hierarchy[\"sections\"] = subsection_hierarchy[\"sections\"]\n",
    "            section_list.append(section_hierarchy)\n",
    "\n",
    "        if section_list:\n",
    "            hierarchy[\"sections\"] = section_list\n",
    "\n",
    "        return hierarchy\n",
    "\n",
    "# Example usage\n",
    "wiki_hierarchy = WikiHierarchy(\"bolt://localhost:7687\", \"neo4j\", \"neo4jpass\")\n",
    "chunk_id = \"3aacf659-c395-452b-92a1-e2e1d2b81ec3\"\n",
    "hierarchy = wiki_hierarchy.get_hierarchy(chunk_id)\n",
    "wiki_hierarchy.close()\n",
    "\n",
    "hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template to encourage LLM to ask for more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question only using the following context. Do not use any external information. \n",
    "\n",
    "Answer with \"I need more context\" in the following situations:\n",
    "- answer is not present in the context\n",
    "- answer is present in the context but you need more context to answer the question\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{query}}\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generator': {'replies': ['I need more context.'], 'meta': [{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 5, 'prompt_tokens': 734, 'total_tokens': 739, 'completion_tokens_details': {'reasoning_tokens': 0}}}]}}\n"
     ]
    }
   ],
   "source": [
    "documents = result[\"joiner\"][\"documents\"]\n",
    "\n",
    "llm_pipeline = Pipeline()\n",
    "llm_pipeline.add_component(instance=PromptBuilder(template=template), name=\"prompt_builder\")\n",
    "llm_pipeline.add_component(\"generator\", generator)\n",
    "llm_pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "\n",
    "result = llm_pipeline.run({\"prompt_builder\": {\"documents\": documents, \"query\": query}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to test whether LLM does not always respond with 'I need more context.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_embedder': {'meta': {'model': 'text-embedding-3-small',\n",
       "   'usage': {'prompt_tokens': 6, 'total_tokens': 6}}},\n",
       " 'joiner': {'documents': [Document(id=f3496c54-52db-4649-b34e-3920c0796e3d, content: '†Carnosauria (large meat-eating dinosaurs; megalosauroids sometimes included)', meta: {'h3': 'Taxonomy', 'split_id': 160.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Classification'}, score: 1.0, embedding: vector of size 1536),\n",
       "   Document(id=bceced15-011d-4c78-9be4-168e32244697, content: 'Scientists will probably never be certain of the largest and smallest dinosaurs to have ever existed...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 201, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}, score: 0.4919354838709677, embedding: vector of size 1536),\n",
       "   Document(id=b99ff952-9244-45b3-88dc-96afdf7850f0, content: '†Ceratosauria (generally elaborately horned carnivores that existed from the Jurassic to Cretaceous ...', meta: {'h3': 'Taxonomy', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 147.0, 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Classification'}, score: 0.4919354838709677, embedding: vector of size 1536)]},\n",
       " 'elasticsearch_retriever': {'documents': [Document(id=f3496c54-52db-4649-b34e-3920c0796e3d, content: '†Carnosauria (large meat-eating dinosaurs; megalosauroids sometimes included)', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 160, 'title': 'Dinosaurs', 'h2': 'Classification', 'h3': 'Taxonomy'}, score: 7.8713713, embedding: vector of size 1536),\n",
       "   Document(id=bceced15-011d-4c78-9be4-168e32244697, content: 'Scientists will probably never be certain of the largest and smallest dinosaurs to have ever existed...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 201, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Size', 'h4': 'Largest and smallest'}, score: 5.2024665, embedding: vector of size 1536),\n",
       "   Document(id=b78f9d4b-eedd-43cf-bd90-8b446803e94d, content: 'Many modern birds are highly social, often found living in flocks. There is general agreement that s...', meta: {'file_path': 'Dinosaur.html', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 206, 'title': 'Dinosaurs', 'h2': 'Paleobiology', 'h3': 'Behavior'}, score: 4.1634035, embedding: vector of size 1536)]},\n",
       " 'weaviate_retriever': {'documents': [Document(id=f3496c54-52db-4649-b34e-3920c0796e3d, content: '†Carnosauria (large meat-eating dinosaurs; megalosauroids sometimes included)', meta: {'h3': 'Taxonomy', 'split_id': 160.0, 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Classification'}, score: 0.8947262763977051, embedding: vector of size 1536),\n",
       "   Document(id=b99ff952-9244-45b3-88dc-96afdf7850f0, content: '†Ceratosauria (generally elaborately horned carnivores that existed from the Jurassic to Cretaceous ...', meta: {'h3': 'Taxonomy', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 147.0, 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Classification'}, score: 0.8498157262802124, embedding: vector of size 1536),\n",
       "   Document(id=7e2ca9b4-dea6-4b04-a136-c33647d6c56d, content: 'Dinosauria', meta: {'h3': 'Taxonomy', 'source_id': '93000a3fb02b99d2d115cd4042256d2f5db2a0ff3928927ca14465276534a75e', 'split_id': 53.0, 'file_path': 'Dinosaur.html', 'title': 'Dinosaurs', 'h4': None, 'h2': 'Classification'}, score: 0.8276913166046143, embedding: vector of size 1536)]}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are Carnosauria?\"\n",
    "\n",
    "result = p.run(data={\"elasticsearch_retriever\": {\"query\": query}, \n",
    "            \"text_embedder\": {\"text\": query}}, include_outputs_from={\"weaviate_retriever\", \"elasticsearch_retriever\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/posthog/client.py:345: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().replace(tzinfo=tzutc())\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:532: ResourceWarning: unclosed  BoltDriver: <neo4j._sync.driver.BoltDriver object at 0x7dae9ab00dd0>.\n",
      "  _unclosed_resource_warn(self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:537: DeprecationWarning: Relying on Driver's destructor to close the session is deprecated. Please make sure to close the session. Use it as a context (`with` statement) or make sure to call `.close()` explicitly. Future versions of the driver will not close drivers automatically.\n",
      "  _deprecation_warn(\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:532: ResourceWarning: unclosed  BoltDriver: <neo4j._sync.driver.BoltDriver object at 0x7dae9a1905c0>.\n",
      "  _unclosed_resource_warn(self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:532: ResourceWarning: unclosed  BoltDriver: <neo4j._sync.driver.BoltDriver object at 0x7dae9a18e5a0>.\n",
      "  _unclosed_resource_warn(self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:532: ResourceWarning: unclosed  BoltDriver: <neo4j._sync.driver.BoltDriver object at 0x7dae9a194d10>.\n",
      "  _unclosed_resource_warn(self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:532: ResourceWarning: unclosed  BoltDriver: <neo4j._sync.driver.BoltDriver object at 0x7dae99729df0>.\n",
      "  _unclosed_resource_warn(self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/neo4j/_sync/driver.py:532: ResourceWarning: unclosed  BoltDriver: <neo4j._sync.driver.BoltDriver object at 0x7dae99719880>.\n",
      "  _unclosed_resource_warn(self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/posthog/request.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  body[\"sentAt\"] = datetime.utcnow().replace(tzinfo=tzutc()).isoformat()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generator': {'replies': ['Carnosauria are large meat-eating dinosaurs; megalosauroids are sometimes included in this group.'], 'meta': [{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 23, 'prompt_tokens': 250, 'total_tokens': 273, 'completion_tokens_details': {'reasoning_tokens': 0}}}]}}\n"
     ]
    }
   ],
   "source": [
    "documents = result[\"joiner\"][\"documents\"]\n",
    "\n",
    "result = llm_pipeline.run({\"prompt_builder\": {\"documents\": documents, \"query\": query}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM works fine - answers 'I need more context.' only when it needs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template to provide page hierarchy information to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_template = \"\"\"\n",
    "The below context provides a Wikipedia page structure in Python dict form - title, h2, h3, h4 sections.\n",
    "Given the question below and given the relevant page hierarchy, think about the section that would contain the answer to the question.\n",
    "\n",
    "Example:\n",
    "If the Dinosaur page has the following structure,\n",
    "{\n",
    "    \"title\": \"Dinosaur\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"name\": \"Overview\",\n",
    "            \"type\": \"h2\",\n",
    "            \"sections\": [\n",
    "                {\n",
    "                    \"name\": \"Etymology\",\n",
    "                    \"type\": \"h3\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "} \n",
    "and the section \"Etymology\" seems to contain the answer to the question \"What does the word dinosaur mean?\", \n",
    "you should repond:\n",
    "Dinosaur -> Overview -> Etymology\n",
    "\n",
    "Note: It is not necessary to always go to the lowest level of the hierarchy. For example if the question is broad and 'Overview' seems to contain the answer,\n",
    "you can respond: Dinosaur -> Overview\n",
    "\n",
    "\n",
    "Context:\n",
    "{{hierarchy}}\n",
    "\n",
    "Question: {{query}}\n",
    "Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/haystack/components/generators/openai.py:106: DeprecationWarning: In the upcoming releases 'gpt-3.5-turbo' will be replaced by 'gpt-4o-mini' as the default model\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7dae9a1964e0>\n",
       "🚅 Components\n",
       "  - hierarchy_prompt_builder: PromptBuilder\n",
       "  - hierarchy_generator: OpenAIGenerator\n",
       "🛤️ Connections\n",
       "  - hierarchy_prompt_builder.prompt -> hierarchy_generator.prompt (str)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "hierarchy_pipeline = Pipeline()\n",
    "hierarchy_pipeline.add_component(instance=PromptBuilder(template=hierarchy_template), name=\"hierarchy_prompt_builder\")\n",
    "hierarchy_pipeline.add_component(instance=OpenAIGenerator(model=\"gpt-4o-mini\"), name=\"hierarchy_generator\")\n",
    "hierarchy_pipeline.connect(\"hierarchy_prompt_builder\", \"hierarchy_generator\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/posthog/client.py:345: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().replace(tzinfo=tzutc())\n",
      "/home/kartikeya/miniconda3/envs/argonk/lib/python3.12/site-packages/posthog/request.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  body[\"sentAt\"] = datetime.utcnow().replace(tzinfo=tzutc()).isoformat()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hierarchy_generator': {'replies': ['Dinosaur -> Paleobiology -> Physiology'], 'meta': [{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 9, 'prompt_tokens': 842, 'total_tokens': 851, 'completion_tokens_details': {'reasoning_tokens': 0}}}]}}\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me in short about the physiology of dinosaurs.\"\n",
    "\n",
    "result = hierarchy_pipeline.run({\"hierarchy_prompt_builder\": {\"hierarchy\": hierarchy, \"query\": query}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hierarchy_generator': {'replies': ['Dinosaur -> Extinction of major groups'], 'meta': [{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 8, 'prompt_tokens': 843, 'total_tokens': 851, 'completion_tokens_details': {'reasoning_tokens': 0}}}]}}\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me a detailed description about how dinosaurs became extinct.\"\n",
    "\n",
    "result = hierarchy_pipeline.run({\"hierarchy_prompt_builder\": {\"hierarchy\": hierarchy, \"query\": query}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good results! LLM goes deep into the hierarchy when required and stops at a higher level if the question is broad enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch relevant chunk ids based on LLM section response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (start, path, idx) { ... }} {position: line: 5, column: 13, offset: 131} for query: '\\n            WITH $path AS path\\n            MATCH (start:Page {title: path[0]})\\n            WITH start, path, 1 AS idx\\n            CALL {\\n                WITH start, path, idx\\n                MATCH (current)-[:HAS_SECTION]->(next)\\n                WHERE current = start AND next.name = path[idx]\\n                WITH next, path, idx + 1 AS next_idx\\n                CALL {\\n                    WITH next, path, next_idx\\n                    MATCH (next)-[:HAS_SECTION*0..]->(subsection)\\n                    WHERE subsection.name = path[next_idx]\\n                    RETURN subsection\\n                    LIMIT 1\\n                }\\n                RETURN subsection\\n            }\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_SECTION*0..]->(subsection)\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_CHUNK]->(chunk:Chunk)\\n            RETURN chunk\\n            '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (next, path, next_idx) { ... }} {position: line: 10, column: 17, offset: 364} for query: '\\n            WITH $path AS path\\n            MATCH (start:Page {title: path[0]})\\n            WITH start, path, 1 AS idx\\n            CALL {\\n                WITH start, path, idx\\n                MATCH (current)-[:HAS_SECTION]->(next)\\n                WHERE current = start AND next.name = path[idx]\\n                WITH next, path, idx + 1 AS next_idx\\n                CALL {\\n                    WITH next, path, next_idx\\n                    MATCH (next)-[:HAS_SECTION*0..]->(subsection)\\n                    WHERE subsection.name = path[next_idx]\\n                    RETURN subsection\\n                    LIMIT 1\\n                }\\n                RETURN subsection\\n            }\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_SECTION*0..]->(subsection)\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_CHUNK]->(chunk:Chunk)\\n            RETURN chunk\\n            '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Node element_id='4:61326856-46d2-4d6e-9ccb-3d3370b8bf1f:243' labels=frozenset({'Chunk'}) properties={'uuid': '6d8ce2b2-dbcf-43bb-a598-4a61a52029ba'}>\n",
      "<Node element_id='4:61326856-46d2-4d6e-9ccb-3d3370b8bf1f:242' labels=frozenset({'Chunk'}) properties={'uuid': '2d9d677d-8d1e-43bd-b800-2d536bf38ecb'}>\n",
      "<Node element_id='4:61326856-46d2-4d6e-9ccb-3d3370b8bf1f:241' labels=frozenset({'Chunk'}) properties={'uuid': '20e258a0-3ef3-413b-89cc-4660319b1847'}>\n",
      "<Node element_id='4:61326856-46d2-4d6e-9ccb-3d3370b8bf1f:240' labels=frozenset({'Chunk'}) properties={'uuid': '54620459-cf76-480a-accf-e8ca14bb6e91'}>\n",
      "<Node element_id='4:61326856-46d2-4d6e-9ccb-3d3370b8bf1f:239' labels=frozenset({'Chunk'}) properties={'uuid': '1e97994a-ccc2-4380-8778-b104f0de2ca3'}>\n",
      "<Node element_id='4:61326856-46d2-4d6e-9ccb-3d3370b8bf1f:238' labels=frozenset({'Chunk'}) properties={'uuid': 'bd119798-6c5e-4805-ae88-147b98d4ba87'}>\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class Neo4jClient:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def get_chunks_by_hierarchy_path(self, path):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"\"\"\n",
    "            WITH $path AS path\n",
    "            MATCH (start:Page {title: path[0]})\n",
    "            WITH start, path, 1 AS idx\n",
    "            CALL {\n",
    "                WITH start, path, idx\n",
    "                MATCH (current)-[:HAS_SECTION]->(next)\n",
    "                WHERE current = start AND next.name = path[idx]\n",
    "                WITH next, path, idx + 1 AS next_idx\n",
    "                CALL {\n",
    "                    WITH next, path, next_idx\n",
    "                    MATCH (next)-[:HAS_SECTION*0..]->(subsection)\n",
    "                    WHERE subsection.name = path[next_idx]\n",
    "                    RETURN subsection\n",
    "                    LIMIT 1\n",
    "                }\n",
    "                RETURN subsection\n",
    "            }\n",
    "            WITH subsection\n",
    "            MATCH (subsection)-[:HAS_SECTION*0..]->(subsection)\n",
    "            WITH subsection\n",
    "            MATCH (subsection)-[:HAS_CHUNK]->(chunk:Chunk)\n",
    "            RETURN chunk\n",
    "            \"\"\", path=path)\n",
    "            return [record[\"chunk\"] for record in result]\n",
    "\n",
    "# Example usage\n",
    "neo4j_client = Neo4jClient(\"bolt://localhost:7687\", \"neo4j\", \"neo4jpass\")\n",
    "path = ['Dinosaur', 'Paleobiology', 'Physiology']\n",
    "chunks = neo4j_client.get_chunks_by_hierarchy_path(path)\n",
    "neo4j_client.close()\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (start, path, idx) { ... }} {position: line: 5, column: 13, offset: 131} for query: '\\n            WITH $path AS path\\n            MATCH (start:Page {title: path[0]})\\n            WITH start, path, 1 AS idx\\n            CALL {\\n                WITH start, path, idx\\n                MATCH (current)-[:HAS_SECTION]->(next)\\n                WHERE current = start AND next.name = path[idx]\\n                WITH next, path, idx + 1 AS next_idx\\n                CALL {\\n                    WITH next, path, next_idx\\n                    MATCH (next)-[:HAS_SECTION*0..]->(subsection)\\n                    WHERE subsection.name = path[next_idx]\\n                    RETURN subsection\\n                    LIMIT 1\\n                }\\n                RETURN subsection\\n            }\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_SECTION*0..]->(subsection)\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_CHUNK]->(chunk:Chunk)\\n            RETURN chunk\\n            '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (next, path, next_idx) { ... }} {position: line: 10, column: 17, offset: 364} for query: '\\n            WITH $path AS path\\n            MATCH (start:Page {title: path[0]})\\n            WITH start, path, 1 AS idx\\n            CALL {\\n                WITH start, path, idx\\n                MATCH (current)-[:HAS_SECTION]->(next)\\n                WHERE current = start AND next.name = path[idx]\\n                WITH next, path, idx + 1 AS next_idx\\n                CALL {\\n                    WITH next, path, next_idx\\n                    MATCH (next)-[:HAS_SECTION*0..]->(subsection)\\n                    WHERE subsection.name = path[next_idx]\\n                    RETURN subsection\\n                    LIMIT 1\\n                }\\n                RETURN subsection\\n            }\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_SECTION*0..]->(subsection)\\n            WITH subsection\\n            MATCH (subsection)-[:HAS_CHUNK]->(chunk:Chunk)\\n            RETURN chunk\\n            '\n"
     ]
    }
   ],
   "source": [
    "neo4j_client = Neo4jClient(\"bolt://localhost:7687\", \"neo4j\", \"neo4jpass\")\n",
    "path = ['Dinosaur', 'Extinction of major groups']\n",
    "chunks = neo4j_client.get_chunks_by_hierarchy_path(path)\n",
    "neo4j_client.close()\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not seem to work correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed results\n",
    "- path = ['Dinosaur', 'Paleobiology', 'Physiology'] seems to work fine, got 6 chunks as expected (did not verify if they are the correct chunks)\n",
    "- path = ['Dinosaur', 'Extinction of major groups'] does not work; expected all chunks under it and chunks of sections/subsections also, but got none! Investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (argonk)",
   "language": "python",
   "name": "argonk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
